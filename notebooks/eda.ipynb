{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploratory Data Analysis - Competitor Pricing Optimizer\n",
        "\n",
        "This notebook performs comprehensive EDA on the product data, including:\n",
        "- Data loading and inspection\n",
        "- Missing value analysis\n",
        "- Feature engineering\n",
        "- Statistical analysis\n",
        "- Correlation analysis\n",
        "- Initial clustering exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load raw data\n",
        "df_raw = pd.read_csv('../data/raw/products.csv')\n",
        "print(f\"Raw data shape: {df_raw.shape}\")\n",
        "df_raw.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load processed data (if available)\n",
        "try:\n",
        "    df_processed = pd.read_csv('../data/processed/products_processed.csv')\n",
        "    print(f\"Processed data shape: {df_processed.shape}\")\n",
        "    df_processed.head()\n",
        "except FileNotFoundError:\n",
        "    print(\"Processed data not found. Run preprocessing first.\")\n",
        "    df_processed = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Overview\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df_raw.copy()\n",
        "\n",
        "print(\"Data Info:\")\n",
        "print(df.info())\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"\\nData Description:\")\n",
        "print(df.describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Missing Values Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "missing_data = df.isnull().sum()\n",
        "missing_pct = (missing_data / len(df)) * 100\n",
        "missing_df = pd.DataFrame({\n",
        "    'Missing Count': missing_data,\n",
        "    'Missing %': missing_pct\n",
        "})\n",
        "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
        "\n",
        "if len(missing_df) > 0:\n",
        "    print(\"Missing Values:\")\n",
        "    print(missing_df)\n",
        "    \n",
        "    # Visualize\n",
        "    fig = px.bar(\n",
        "        missing_df.reset_index(),\n",
        "        x='index',\n",
        "        y='Missing %',\n",
        "        title='Missing Values by Column',\n",
        "        labels={'index': 'Column', 'Missing %': 'Missing Percentage'}\n",
        "    )\n",
        "    fig.update_layout(height=400)\n",
        "    fig.show()\n",
        "else:\n",
        "    print(\"No missing values found!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Feature Distribution Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Price distribution\n",
        "fig = make_subplots(\n",
        "    rows=2, cols=2,\n",
        "    subplot_titles=('Price Distribution', 'Rating Distribution', 'Reviews Distribution', 'Price vs Rating'),\n",
        "    specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
        "           [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
        ")\n",
        "\n",
        "# Price histogram\n",
        "fig.add_trace(\n",
        "    go.Histogram(x=df['price'], nbinsx=50, name='Price'),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# Rating histogram\n",
        "fig.add_trace(\n",
        "    go.Histogram(x=df['rating'], nbinsx=20, name='Rating'),\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "# Reviews histogram\n",
        "fig.add_trace(\n",
        "    go.Histogram(x=df['reviews_count'], nbinsx=50, name='Reviews'),\n",
        "    row=2, col=1\n",
        ")\n",
        "\n",
        "# Scatter plot\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=df['price'], y=df['rating'], mode='markers', name='Price vs Rating'),\n",
        "    row=2, col=2\n",
        ")\n",
        "\n",
        "fig.update_layout(height=800, showlegend=False, title_text=\"Feature Distributions\")\n",
        "fig.update_xaxes(title_text=\"Price (₹)\", row=1, col=1)\n",
        "fig.update_xaxes(title_text=\"Rating\", row=1, col=2)\n",
        "fig.update_xaxes(title_text=\"Reviews Count\", row=2, col=1)\n",
        "fig.update_xaxes(title_text=\"Price (₹)\", row=2, col=2)\n",
        "fig.update_yaxes(title_text=\"Count\", row=1, col=1)\n",
        "fig.update_yaxes(title_text=\"Count\", row=1, col=2)\n",
        "fig.update_yaxes(title_text=\"Count\", row=2, col=1)\n",
        "fig.update_yaxes(title_text=\"Rating\", row=2, col=2)\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'brand' in df.columns:\n",
        "    brand_stats = df.groupby('brand').agg({\n",
        "        'price': ['mean', 'std', 'count'],\n",
        "        'rating': 'mean',\n",
        "        'reviews_count': 'mean'\n",
        "    }).round(2)\n",
        "    \n",
        "    brand_stats.columns = ['Avg Price', 'Price Std', 'Product Count', 'Avg Rating', 'Avg Reviews']\n",
        "    brand_stats = brand_stats.sort_values('Avg Price', ascending=False)\n",
        "    \n",
        "    print(\"Brand Statistics:\")\n",
        "    print(brand_stats)\n",
        "    \n",
        "    # Visualize\n",
        "    fig = px.bar(\n",
        "        brand_stats.reset_index(),\n",
        "        x='brand',\n",
        "        y='Avg Price',\n",
        "        title='Average Price by Brand',\n",
        "        labels={'brand': 'Brand', 'Avg Price': 'Average Price (₹)'}\n",
        "    )\n",
        "    fig.update_layout(height=400)\n",
        "    fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Correlation Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select numeric columns\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "corr_matrix = df[numeric_cols].corr()\n",
        "\n",
        "# Heatmap\n",
        "fig = px.imshow(\n",
        "    corr_matrix,\n",
        "    labels=dict(color=\"Correlation\"),\n",
        "    x=corr_matrix.columns,\n",
        "    y=corr_matrix.columns,\n",
        "    color_continuous_scale='RdBu',\n",
        "    title='Correlation Heatmap'\n",
        ")\n",
        "fig.update_layout(height=600)\n",
        "fig.show()\n",
        "\n",
        "print(\"\\nCorrelation Matrix:\")\n",
        "print(corr_matrix.round(3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Feature Engineering Preview\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate derived features\n",
        "df['discount_pct'] = ((df['original_price'] - df['price']) / df['original_price'] * 100).fillna(0)\n",
        "df['demand_proxy'] = df['rating'] * df['reviews_count']\n",
        "df['price_per_rating'] = df['price'] / (df['rating'] + 0.1)\n",
        "\n",
        "print(\"Engineered Features:\")\n",
        "print(df[['discount_pct', 'demand_proxy', 'price_per_rating']].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Initial Clustering Exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Prepare features for clustering\n",
        "features = ['price', 'rating', 'reviews_count', 'demand_proxy']\n",
        "X = df[features].fillna(df[features].median())\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Test different numbers of clusters\n",
        "silhouette_scores = []\n",
        "inertias = []\n",
        "k_range = range(2, 10)\n",
        "\n",
        "for k in k_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    labels = kmeans.fit_predict(X_scaled)\n",
        "    silhouette_scores.append(silhouette_score(X_scaled, labels))\n",
        "    inertias.append(kmeans.inertia_)\n",
        "\n",
        "# Plot elbow curve\n",
        "fig = make_subplots(\n",
        "    rows=1, cols=2,\n",
        "    subplot_titles=('Elbow Method', 'Silhouette Score'),\n",
        "    specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=list(k_range), y=inertias, mode='lines+markers', name='Inertia'),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=list(k_range), y=silhouette_scores, mode='lines+markers', name='Silhouette Score'),\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "fig.update_layout(height=400, title_text=\"Clustering Analysis\")\n",
        "fig.update_xaxes(title_text=\"Number of Clusters\", row=1, col=1)\n",
        "fig.update_xaxes(title_text=\"Number of Clusters\", row=1, col=2)\n",
        "fig.update_yaxes(title_text=\"Inertia\", row=1, col=1)\n",
        "fig.update_yaxes(title_text=\"Silhouette Score\", row=1, col=2)\n",
        "\n",
        "fig.show()\n",
        "\n",
        "optimal_k = k_range[np.argmax(silhouette_scores)]\n",
        "print(f\"\\nOptimal number of clusters: {optimal_k} (Silhouette Score: {max(silhouette_scores):.3f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"KEY INSIGHTS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\n1. Total Products: {len(df)}\")\n",
        "print(f\"2. Price Range: ₹{df['price'].min():,.0f} - ₹{df['price'].max():,.0f}\")\n",
        "print(f\"3. Average Price: ₹{df['price'].mean():,.0f}\")\n",
        "print(f\"4. Average Rating: {df['rating'].mean():.2f}\")\n",
        "print(f\"5. Total Reviews: {df['reviews_count'].sum():,}\")\n",
        "\n",
        "if 'brand' in df.columns:\n",
        "    top_brand = df.groupby('brand')['price'].mean().idxmax()\n",
        "    print(f\"6. Highest Priced Brand: {top_brand}\")\n",
        "\n",
        "print(f\"\\n7. Optimal Clusters: {optimal_k}\")\n",
        "print(\"=\"*60)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
